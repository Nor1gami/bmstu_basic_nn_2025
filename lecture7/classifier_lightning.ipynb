{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86ab56b9",
   "metadata": {},
   "source": [
    "\n",
    "# Семинар 7 (part1): GradCam\n",
    "\n",
    "В рамках данного семинара рассмотрим подробно модуль lightning.pytorch. Обучим классификационную сеть на датасете СARS196, который является бенчмарком для задачи metric-learning: https://paperswithcode.com/sota/metric-learning-on-cars196\n",
    "\n",
    "Данные можно найти по ссылкам:\n",
    "* meta : https://drive.google.com/file/d/1PD-lbbcKSelDeAYKafe3boc5mqqEe7X7/view?usp=sharing\n",
    "* data : https://drive.google.com/file/d/1l9EnYMC-xGX706SY1kN8RceMmFViASfx/view?usp=sharing\n",
    "\n",
    "А также рассмотрим библиотеку GradCam для интерпретации работы моделей компьютерного зрения:\n",
    "repo - https://github.com/jacobgil/pytorch-grad-cam\n",
    "paper - https://arxiv.org/abs/1610.02391"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343785f7",
   "metadata": {},
   "source": [
    "### Познакомимся с данными\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "25c183e8-8a98-4b41-8691-c4524f4be992",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "!pip install typing_extensions==4.8.0\n",
    "!pip install torch==2.4.1 torchvision\n",
    "!pip install lightning pytorch-lightning timm\n",
    "!pip install opencv-python-headless\n",
    "!pip install grad_cam"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fc1da0cc",
   "metadata": {},
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "device = 'cuda'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b8048c8e",
   "metadata": {},
   "source": [
    "import scipy.io\n",
    "mat = scipy.io.loadmat('./devkit/cars_train_annos.mat')\n",
    "fname_to_class = {fname:cl-1 for fname, cl in zip([i[0] for i in mat['annotations'][0]['fname']], \n",
    "                                                [i[0][0] for i in mat['annotations'][0]['class']])}\n",
    "cars_meta = scipy.io.loadmat('./devkit/cars_meta.mat')\n",
    "id_to_car = {idx: car[0] for idx, car in enumerate(cars_meta['class_names'][0])}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2e948c2f",
   "metadata": {},
   "source": [
    "ADD_PATH = './cars_train'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0ce6470b",
   "metadata": {},
   "source": [
    "num_imgs = 9\n",
    "cols = 3\n",
    "rows = num_imgs // cols\n",
    "fig, ax = plt.subplots(rows, cols, figsize = (15, 15))\n",
    "for idx, im_idx in enumerate(random.sample([i for i in range(len(fname_to_class))], num_imgs)):\n",
    "    filename, cl_id = list(fname_to_class.items())[im_idx]\n",
    "    temp_image = cv2.imread(os.path.join(ADD_PATH, filename))\n",
    "    temp_image = cv2.cvtColor(temp_image, cv2.COLOR_BGR2RGB)\n",
    "    ax[idx//cols][idx%cols].imshow(temp_image)\n",
    "    ax[idx//cols][idx%cols].set_title(f'{id_to_car[cl_id]}')\n",
    "    ax[idx//cols][idx%cols].axis('off')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "314493c0",
   "metadata": {},
   "source": [
    "plt.hist(fname_to_class.values())\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "25c8f1e8",
   "metadata": {},
   "source": [
    "### Реализуем обертку для данных"
   ]
  },
  {
   "cell_type": "code",
   "id": "3df597e7",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "val_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToPILImage(),\n",
    "    torchvision.transforms.Resize(\n",
    "        size=(224, 224)\n",
    "    ),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "class CropClassifDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, cars_items, transforms):\n",
    "        self.cars = cars_items\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.cars)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename, cl_id = self.cars[idx]\n",
    "        image = cv2.imread(os.path.join(ADD_PATH, filename))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        sample = {'image': image, 'label': cl_id}\n",
    "        return sample"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d9f03589",
   "metadata": {},
   "source": [
    "items = list(fname_to_class.items())\n",
    "random.shuffle(items)\n",
    "train_items = items[:int(len(items) * 0.8)]\n",
    "val_items = items[int(len(items) * 0.8):]\n",
    "\n",
    "train_dataset = CropClassifDataset(train_items, val_transforms)\n",
    "val_dataset = CropClassifDataset(val_items, val_transforms)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "34720d02",
   "metadata": {},
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, collate_fn=None, pin_memory=True, drop_last = True)\n",
    "valid_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4, collate_fn=None, pin_memory=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "981641ba",
   "metadata": {},
   "source": [
    "### Обучим модель"
   ]
  },
  {
   "cell_type": "code",
   "id": "ee75df9a",
   "metadata": {},
   "source": [
    "from timm.scheduler import TanhLRScheduler\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from timm.scheduler import TanhLRScheduler\n",
    "from lightning.pytorch.callbacks import LearningRateMonitor\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "class CarClassifier(pl.LightningModule):\n",
    "    def __init__(self, class_dict, learning_rate, emb_size = 512):\n",
    "        super().__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.class_dict = class_dict\n",
    "        \n",
    "        self.model = resnet50()\n",
    "        \n",
    "        #Because no network\n",
    "        model_weights = 'resnet50-0676ba61.pth'\n",
    "        state_dict = torch.load(model_weights)\n",
    "        self.model.load_state_dict(state_dict)\n",
    "        # Else\n",
    "        # self.model = resnet50(pretrained=True)\n",
    "        \n",
    "        self.model.fc = torch.nn.Sequential(\n",
    "                            torch.nn.Linear(in_features=2048, out_features=emb_size),\n",
    "                            torch.nn.ReLU(inplace=False),\n",
    "                            torch.nn.Linear(in_features=emb_size, out_features=len(class_dict)))\n",
    "                        \n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images = batch['image']\n",
    "        labels = batch['label'].to(torch.long)\n",
    "        preds = self.model(images)\n",
    "        loss = self.criterion(preds, labels)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images = batch['image']\n",
    "        labels = batch['label'].to(torch.long)\n",
    "        preds = self.model(images)\n",
    "        loss = self.criterion(preds, labels)\n",
    "        self.log(\"validation_loss\", loss, sync_dist=True)\n",
    "        self.log(\"validation_accuracy\", torch.sum(torch.argmax(preds, dim = 1) == labels).item() / torch.tensor(labels.shape).item(), sync_dist=True)\n",
    "        \n",
    "    def forward(self, images):\n",
    "        if len(images.shape) == 4:\n",
    "            preds = self.model(images) \n",
    "        else:\n",
    "            preds = self.model(images.unsqueeze(0))\n",
    "        preds = [self.class_dict[i.argmax().item()] for i in preds]\n",
    "        return preds\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return [optimizer]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "78b7f8bb",
   "metadata": {},
   "source": [
    "# model\n",
    "pl_model = CarClassifier(id_to_car, 3e-4)\n",
    "checkpoint_callback = ModelCheckpoint(monitor='validation_accuracy', mode='max', save_top_k=3)\n",
    "# last_checkpoint = ModelCheckpoint(mode='max', monitor='time_log', save_top_k=1)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"validation_loss\", mode=\"min\", patience=2)\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "# train model\n",
    "trainer = pl.Trainer(max_epochs=20, accelerator=device, devices = 4, callbacks=[checkpoint_callback, early_stopping, lr_monitor])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "31f9a737",
   "metadata": {},
   "source": [
    "trainer.fit(model=pl_model, train_dataloaders=train_loader, \n",
    "            val_dataloaders=valid_loader)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "06b370bd",
   "metadata": {},
   "source": [
    "trainer.validate(model=pl_model, dataloaders=valid_loader)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5acee5ae",
   "metadata": {},
   "source": [
    "# GradCam\n",
    "\n",
    "Данный фреймворк предназначен для интерпретации моделей компьютерного зрения на основе карт активации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a9a762",
   "metadata": {},
   "source": [
    "![Drag Racing](images/cam-structure.png)"
   ]
  },
  {
   "cell_type": "code",
   "id": "10e30912",
   "metadata": {},
   "source": [
    "from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c7d38fc2",
   "metadata": {},
   "source": [
    "transform_to_show = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToPILImage(), \n",
    "    torchvision.transforms.Resize(\n",
    "        size=(224, 224)\n",
    "    ),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "def show_grad_cam(model, num_imgs):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    cols = 3\n",
    "    rows = num_imgs // cols\n",
    "    fig, ax = plt.subplots(rows, cols, figsize = (15, 15))\n",
    "    for idx, im_idx in enumerate(random.sample([i for i in range(len(fname_to_class))], num_imgs)):\n",
    "        filename, cl_id = list(fname_to_class.items())[im_idx]\n",
    "        temp_image = cv2.imread(os.path.join(ADD_PATH, filename))\n",
    "        temp_image = cv2.cvtColor(temp_image, cv2.COLOR_BGR2RGB)\n",
    "        rgb_im = np.array(transform_to_show(temp_image).permute(1,2,0))\n",
    "        transformed_im = val_transforms(temp_image).unsqueeze(0).to(device)\n",
    "        target_layers = [model.layer4]\n",
    "        cam = GradCAM(model=model, target_layers=target_layers)\n",
    "        grayscale_cam = cam(input_tensor=transformed_im)\n",
    "        grayscale_cam = grayscale_cam[0, :]\n",
    "        visualization = show_cam_on_image(rgb_im, grayscale_cam, use_rgb=True)\n",
    "        pred = id_to_car[model(transformed_im).argmax().item()]\n",
    "        ax[idx//cols][idx%cols].imshow(visualization)\n",
    "        ax[idx//cols][idx%cols].set_title(f'gt : {id_to_car[cl_id]} \\n pred: {pred}')\n",
    "        ax[idx//cols][idx%cols].axis('off')\n",
    "\n",
    "\n",
    "def show_diff_grad_methods(model, methods):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    num_imgs = 4\n",
    "    rows = len(methods)\n",
    "    fig, ax = plt.subplots(rows, num_imgs, figsize = (30, 30))\n",
    "    random_images = random.sample([i for i in range(len(fname_to_class))], num_imgs)\n",
    "    for row_id, method in enumerate(methods):\n",
    "        for col_id, im_idx in enumerate(random_images):\n",
    "            filename, cl_id = list(fname_to_class.items())[im_idx]\n",
    "            temp_image = cv2.imread(os.path.join(ADD_PATH, filename))\n",
    "            temp_image = cv2.cvtColor(temp_image, cv2.COLOR_BGR2RGB)\n",
    "            rgb_im = np.array(transform_to_show(temp_image).permute(1,2,0))\n",
    "            transformed_im = val_transforms(temp_image).unsqueeze(0).to(device)\n",
    "            target_layers = [model.layer4]\n",
    "            cam = method(model=model, target_layers=target_layers)\n",
    "            grayscale_cam = cam(input_tensor=transformed_im)\n",
    "            grayscale_cam = grayscale_cam[0, :]\n",
    "            visualization = show_cam_on_image(rgb_im, grayscale_cam, use_rgb=True)\n",
    "            ax[row_id][col_id].imshow(visualization)\n",
    "            ax[row_id][col_id].set_title(f\"method : {str(method).split('.')[-1][:-2]} \\n gt : {id_to_car[cl_id]}\")\n",
    "            ax[row_id][col_id].axis('off')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dd2d1cca",
   "metadata": {},
   "source": [
    "### посмотрим на различные методы"
   ]
  },
  {
   "cell_type": "code",
   "id": "4eaeaf00",
   "metadata": {},
   "source": [
    "show_diff_grad_methods(pl_model.model, [ GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1eb9ab45-ea52-48c5-b40a-1e1b487b80af",
   "metadata": {},
   "source": [
    "show_grad_cam(pl_model.model, num_imgs)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c6b6781d",
   "metadata": {},
   "source": [
    "### Cравним перфоманс различных моделей и посмотрим на ошибки"
   ]
  },
  {
   "cell_type": "code",
   "id": "a32843a4",
   "metadata": {},
   "source": [
    "t = CarClassifier(id_to_car, 3e-4)\n",
    "show_grad_cam(t.model, num_imgs)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1a9720d8",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7f927295",
   "metadata": {},
   "source": [
    "t = resnet50(pretrained=False)\n",
    "t.fc = torch.nn.Sequential(\n",
    "                            torch.nn.Linear(in_features=2048, out_features=512),\n",
    "                            torch.nn.ReLU(inplace=False),\n",
    "                            torch.nn.Linear(in_features=512, out_features=len(id_to_car)))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c520d902",
   "metadata": {},
   "source": [
    "show_grad_cam(t, num_imgs)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6b8e25ca",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9324d0db-5730-4246-9b38-8a358e46c85b",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
